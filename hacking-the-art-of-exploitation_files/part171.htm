<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>0x720 Algorithmic Run Time</title><link href="navigation.css" rel="stylesheet" type="text/css"/><link href="document.css" rel="stylesheet" type="text/css"/></head><body><p class="top_nav"><a href="part170.htm">&lt; Previous</a><span> | </span><a href="../hacking-the-art-of-exploitation.html">Contents</a><span> | </span><a href="part172.htm">Next &gt;</a></p><p class="s30" style="padding-top: 3pt;padding-left: 37pt;text-indent: 0pt;text-align: left;"><a name="bookmark156">0x720 Algorithmic Run Time</a></p><p class="s27" style="padding-top: 7pt;padding-left: 91pt;text-indent: 0pt;line-height: 106%;text-align: justify;">Algorithmic run time <span class="p">is a bit different from the run time of a program. Since an algorithm is simply an idea, there’s no limit to the processing speed for evaluating the algorithm. This means that an expression of algorithmic run time in minutes or seconds is meaningless.</span></p><p style="padding-left: 91pt;text-indent: 17pt;line-height: 106%;text-align: left;">Without factors such as processor speed and architecture, the important unknown for an algorithm is <span class="s27">input size</span>. A sorting algorithm running on 1,000 elements will certainly take longer than the same sorting algorithm running on 10 elements. The input size is generally denoted by <span class="s27">n</span>, and each atomic step can be expressed as a number. The run time of a simple algorithm, such as the one that follows, can be expressed in terms of <span class="s27">n</span>.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 91pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="444" height="1" alt="image" src="Image_1216.png"/></span></p><p class="s31" style="padding-left: 104pt;text-indent: -12pt;text-align: left;">for(i = 1 to n) { Do something;</p><p class="s31" style="padding-left: 104pt;text-indent: 0pt;line-height: 10pt;text-align: left;">Do another thing;</p><p class="s31" style="padding-left: 91pt;text-indent: 0pt;text-align: left;">}</p><p class="s31" style="padding-bottom: 3pt;padding-left: 91pt;text-indent: 0pt;text-align: left;">Do one last thing;</p><p style="padding-left: 91pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="444" height="1" alt="image" src="Image_1217.png"/></span></p><p style="padding-top: 6pt;padding-left: 91pt;text-indent: 18pt;text-align: left;">This algorithm loops <span class="s27">n </span>times, each time doing two actions, and then does one last action, so the <span class="s27">time complexity </span>for this algorithm would be 2<span class="s27">n </span>+ 1. A more complex algorithm with an additional nested loop tacked on, shown below, would have a time complexity of <span class="s27">n</span><span class="s41">2</span> + 2<span class="s27">n </span>+ 1, since the new action is executed <span class="s27">n</span><span class="s41">2</span> times.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 91pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="444" height="1" alt="image" src="Image_1218.png"/></span></p><p class="s31" style="padding-left: 104pt;text-indent: -12pt;text-align: left;">for(x = 1 to n) { for(y = 1 to n) {</p><p class="s31" style="padding-left: 116pt;text-indent: 0pt;text-align: left;">Do the new action;</p><p class="s31" style="padding-left: 104pt;text-indent: 0pt;text-align: left;">}</p><p class="s31" style="padding-left: 91pt;text-indent: 0pt;text-align: left;">}</p><p class="s31" style="padding-left: 104pt;text-indent: -12pt;text-align: left;">for(i = 1 to n) { Do something;</p><p class="s31" style="padding-left: 104pt;text-indent: 0pt;line-height: 10pt;text-align: left;">Do another thing;</p><p class="s31" style="padding-left: 91pt;text-indent: 0pt;text-align: left;">}</p><p class="s31" style="padding-bottom: 3pt;padding-left: 91pt;text-indent: 0pt;text-align: left;">Do one last thing;</p><p style="padding-left: 91pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="444" height="1" alt="image" src="Image_1219.png"/></span></p><p style="padding-top: 6pt;padding-left: 91pt;text-indent: 18pt;text-align: left;">But this level of detail for time complexity is still too granular. For example, as <span class="s27">n </span>becomes larger, the relative difference between 2<span class="s27">n </span>+ 5 and 2<span class="s27">n </span>+ 365 becomes less and less. However, as <span class="s27">n </span>becomes larger, the relative difference between 2<span class="s27">n</span><span class="s41">2</span> + 5 and 2<span class="s27">n </span>+ 5 becomes larger and larger. This type of generalized trending is what is most important to the run time of an algorithm.</p><p style="padding-left: 91pt;text-indent: 18pt;text-align: left;">Consider two algorithms, one with a time complexity of 2<span class="s27">n </span>+ 365 and the other with 2<span class="s27">n</span><span class="s41">2</span> + 5. The 2<span class="s27">n</span><span class="s41">2</span> + 5 algorithm will outperform the 2<span class="s27">n </span>+ 365 algorithm on small values for <span class="s27">n</span>. But for <span class="s27">n </span>= 30, both algorithms perform equally, and for all <span class="s27">n </span>greater than 30, the 2<span class="s27">n </span>+ 365 algorithm will outperform the 2<span class="s27">n</span><span class="s41">2</span> + 5 algorithm. Since there are only 30 values for <span class="s27">n </span>in which the</p><p style="padding-left: 91pt;text-indent: 0pt;text-align: left;">2<span class="s27">n</span><span class="s41">2</span> + 5 algorithm performs better, but an infinite number of values for <span class="s27">n </span>in which the 2<span class="s27">n </span>+ 365 algorithm performs better, the 2<span class="s27">n </span>+ 365 algorithm is generally more efficient.</p><p style="padding-top: 3pt;padding-left: 91pt;text-indent: 17pt;line-height: 108%;text-align: left;">This means that, in general, the growth rate of the time complexity of an algorithm with respect to input size is more important than the time com- plexity for any fixed input. While this might not always hold true for specific real-world applications, this type of measurement of an algorithm’s efficiency tends to be true when averaged over all possible applications.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="nav">&nbsp;&nbsp;</p><p class="nav">&nbsp;</p><p class="nav"><a href="part170.htm">&lt; Previous</a><span> | </span><a href="../hacking-the-art-of-exploitation.html">Contents</a><span> | </span><a href="part172.htm">Next &gt;</a></p><p class="nav">&nbsp;&nbsp;</p></body></html>
